---
title: 人工智能三大瓶颈-姚期智
typora-root-url: ../../source
typora-copy-images-to: ../images/AI-yaoqizhi.assets
mathjax: true
categories: AI
tags:
- 人工智能
---

#### 姚期智在2020年浦江创新论坛的演讲：

**人工智能存在三大技术瓶颈：**

**鲁棒性、机器学习算法缺乏可解释性、人工智能的对抗性较弱**

#### 一. 鲁棒性

<!--more-->

关于鲁棒性问题，可以解释成脆弱性、非安全性、非可靠性问题。人工智能系统设计历来重功能性设计，轻可靠性、安全性设计；或先功能性，后安全性、可靠性。

在早期产品中这一现象尤为严重。在自动驾驭汽车领域，最终制约因素是安全性、可靠性问题，未来，无人驾驶汽车研发会因可靠性、安全性问题，成为“永在途中”的课题。

在姚期智看来，脆弱性是人工智能面临的第一大技术瓶颈。人眼识别十分稳定，一个图像如有微小改变，人仍能一眼看出它是什么，而人工智能在图像识别上却是能力不足，比如将一只小猪的照片加入一些图像“杂音”，机器视觉系统可能会把它识别为飞机。“小猪变飞机”这种漏洞会给人工智能应用带来安全隐患。

#### 二. 可解释性

关于可解释性，可以理解成广义的开源性。可解释性就是如何让人们深入了解人工智能系统。以汽车为例，在工业革命时代，汽车驾驶者们对汽车原理、结构一目了然；现在，汽车对于驾驶员而言只是一个黑盒子，只有方向盘、油门、刹车这样一个应用界面。

相比而言，工业革命时代的汽车有高度的可解释性，人工智能的新兴汽车无可解释性。同样，手机、数码相机、电视机相较于电话机、照相机、电子管电视机而言，无可解释性，对所有使用者都是黑盒子，无人去拆解、修理，去了解其内部结构，这是一种十分现实、十分先进的人工智能产品的傻瓜化应用模式，它将知识创新与创新知识应用彻底分离。

然而，对于人工智能创新领域，不可解释性是一个技术创新的巨大障碍。硬件的透明、软件的开源，一定程度上解决了技术创新的可解释性障碍。目前，可解释性障碍突出表现在算法领域（人工智能三大基础之一），它阻碍算法的推广、评价与市场化，算法的碎片化现象会严重阻碍人工智能的发展。

#### 三. 对抗性

第三大技术瓶颈是人工智能的对抗性较弱。

如今，一个无人机群可轻松完成灯光秀、农林作业等任务，但要看到，这些任务都是在自然环境下完成，如果是处于高对抗的人为环境中呢？

比如在电子竞技和军事战斗中，无人机群的协同作战能力就会受到很大考验，要在对抗中胜出，需要计算机科学、数学等领域的科学家进行深入的强化学习、博弈论研究，让无人机群能在高对抗环境中自主找到最优策略。“这是一个很重要的科研方向。

早年在清华大学的一次演讲中，他提出了人工智能时代的“大科学”概念。它表明：人工智能时代，已进入到诸多强势科学的交叉融合发展时代，各个强势学科都会以自己的视角诠释人工智能。

此次演中，姚期智提到超人工智能，并提出对超人工智能的三点期望。过去人们一直把人工智能分成弱人工智能与强人工智能。

弱人工智能始于半导体微处理器诞生，是对人类智力的人工仿真；强人工智能始于大脑工程，是人工智能的智力创新时代。

由于人工智能超高速度的疯狂发展，人们无法预见人工智能的未来，便有了后强人工智能的超人工智能概念。姚期智认为超人工智能具有很大的不确定性，人类会面对诸多种潜在威胁。

#### 对于超人工智能的未来，姚期智给出了未来制约智能机器的三个原则：

一是利他，即人的利益凌驾于机器；

二是谦卑，即机器不能自以为是；

三是尽心，即机器能学懂人的偏好。每个原则都要用严格的算法来实现，这样就能有效驾驭人工智能。

这是一个对未知时代的理性期望，希望人工智能最终能走向理性化道路。